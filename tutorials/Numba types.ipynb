{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import numba\n",
      "import numpy as np\n",
      "import math\n",
      "import llvm\n",
      "import ctypes\n",
      "print(\"numba version: %s \\nNumPy version: %s\\nllvm version: %s\" % (numba.__version__,np.__version__, llvm.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "numba version: 0.11.1-2-gf56bd17 \n",
        "NumPy version: 1.7.1\n",
        "llvm version: 0.12.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Numba and types"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Numba* translates *Python* code into fast executing native code. In order to generate fast native code, many dynamic features of *Python* need to be translated into static equivalents. This includes dynamic typing as well as polymorphism. The approach taken in *numba* is using *type inference* to generate *type information* for the code, so that it is possible to translate into native code. If all the values in a *numba* compiled function can be translated into native types, the resulting code will be competitive with that generated with a low level language. \n",
      "\n",
      "The objective of *type inference* is assigning a *type* to every single value in the function. The *type* of a value can either be:\n",
      "\n",
      "* *Implicit*, in the case of providing an object that will provide its *type*. This happens, for example, in literals.\n",
      "* *Explicit*, in the case of the programmer explicitly writing the *type* of a given value. This happens, for example, when a signature is given to *numba.jit*. That signature explicitly *types* the arguments.\n",
      "* *Inferred*, when the *type* is deduced from an operation and the types of the its operands. For example, inferring that the type of *a + b*, when *a* and *b* are of type *int* is going to be an *int*\n",
      "\n",
      "*Type inference* is the process by which all the *types* that are neither *implicit* nor *explicit* are deduced."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Typing in a sample function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take a very simple sample function to illustrate these concepts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sample_func(n):\n",
      "    tmp = n + 4;\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When translating to native code it is needed to provide *type information* for every value involved in the sample function. This will include:\n",
      "\n",
      "* The *literals* **4** and **3j**. These two have an implicit type.\n",
      "* The argument **n**. In the function, as is, it is yet untyped.\n",
      "* Some intermediate values, like **tmp** and the **return value**. Their type is not known yet."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding out the *types* of values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can use the function *numba.typeof* to find out the *numba type* associated to a value. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(numba.typeof.__doc__)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    Get the type of a variable or value.\n",
        "\n",
        "    Used outside of Numba code, infers the type for the object.\n",
        "    \n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bear in mind that, when used from the *Python* interpreter, *numba.typeof* will return the *numba type* associated to the object passed as parameter. For example, let's try using it on the *literals* found in our sample function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "int"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(3j)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also note that the types of the results are *numba types*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(numba.typeof(4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "numba.typesystem.types._NumbaType"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a note, when used inside *numba* compiled code, *numba.typeof* will return the type as inferred during *type inference*. This may be a more general *type* than the one which would be returned when evaluating using the *Python interpreter*."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "*Type inference* in *numba.jit*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When using *numba.jit*, we provide *explicit typing* to the arguments of the function in the form of the *signature*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit('c16(f8)')\n",
      "def jit_sample_1(n):\n",
      "    tmp = n + 4;\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, we provide information saying that the argument *n* is going to be an *8 byte float* (a typical *double precision floating point number*). The result will be a *16 byte complex* (a typical *double precision complex*).\n",
      "\n",
      "The types of different values can be checked by printing the *numba.typeof* of different values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit('c16(f8)')\n",
      "def jit_sample_1(n):\n",
      "    print('arg n: '+ str(numba.typeof(n)))\n",
      "    print('literal 4: ' + str(numba.typeof(4))) \n",
      "    tmp = n + 4;\n",
      "    print('tmp: '+ str(numba.typeof(tmp)))\n",
      "    print('literal 3j:' + str(numba.typeof(3j)))\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(jit_sample_1(42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: float64\n",
        "literal 4: int\n",
        "tmp: float64\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As can be seen, the types of intermediate values have been filled automatically, and the return value is a complex128. Note that the type strings used in the signature are NumPy based, and use the number of *bytes* to denote the size of the type. However, the types itself use the number of *bits* in the type. So **'f8'** is equivalent to *float64* and **'c16'** is equivalent to *complex128*.\n",
      "\n",
      "If instead of using a *float64* as type for the argument we had used, say, an *int8*, the intermediate values would be a bit different:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit('c16(i1)')\n",
      "def jit_sample_2(n):\n",
      "    print('arg n: '+ str(numba.typeof(n)))\n",
      "    print('literal 4: ' + str(numba.typeof(4))) \n",
      "    tmp = n + 4;\n",
      "    print('tmp: '+ str(numba.typeof(tmp)))\n",
      "    print('literal 3j:' + str(numba.typeof(3j)))\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(jit_sample_2(42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: int8\n",
        "literal 4: int\n",
        "tmp: int32\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to specify explicit types for variables by using a the *locals* keyword in *numba.jit*. This allows explicit typing of a variable. In our last example we could use this to, for example, force *tmp* to be a 16 bit integer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit('c16(i1)', locals={'tmp': numba.int16})\n",
      "def jit_sample_3(n):\n",
      "    print('arg n: '+ str(numba.typeof(n)))\n",
      "    print('literal 4: ' + str(numba.typeof(4))) \n",
      "    tmp = n + 4;\n",
      "    print('tmp: '+ str(numba.typeof(tmp)))\n",
      "    print('literal 3j:' + str(numba.typeof(3j)))\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(jit_sample_3(42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: int8\n",
        "literal 4: int\n",
        "tmp: int16\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "*Type inference* in *numba.autojit*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As opposed to *numba.jit*, in *numba.autojit* no signature is explicitly provided to the function. This is because *numba.autojit* automatically chooses at run-time the specialization to use based on the types of the arguments for that call. In the case that no specialization is available, it compiles the specialization.\n",
      "\n",
      "In general, the process of *type inference* is similar in both *numba.jit* and *numba.autojit*. The only difference is that in *numba.jit* an *explicit signature* is provided. In jit a single compilation in built for that specific *signature*. With *numba.autojit* a signature is inferred from the actual objects passed as arguments in a call. *Numba* compiles the function for that *inferred signature* and calls it. There is caching under the hood, so a given function is only compiled once with a given *signature*.\n",
      "\n",
      "Going back to our example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.autojit\n",
      "def autojit_sample(n):\n",
      "    print('arg n: '+ str(numba.typeof(n)))\n",
      "    print('literal 4: ' + str(numba.typeof(4))) \n",
      "    tmp = n + 4;\n",
      "    print('tmp: '+ str(numba.typeof(tmp)))\n",
      "    print('literal 3j:' + str(numba.typeof(3j)))\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(autojit_sample(42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: int\n",
        "literal 4: int\n",
        "tmp: int\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(autojit_sample(42.0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: float64\n",
        "literal 4: int\n",
        "tmp: float64\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(autojit_sample(42 + 0j))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: complex128\n",
        "literal 4: int\n",
        "tmp: complex128\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In all three cases a new version of the function is compiled. In each cases the types of the arguments/intermediate values differ slightly.\n",
      "\n",
      "It is also possible to use the *locals* keyword with *autojit*: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.autojit(locals={'tmp': numba.complex64})\n",
      "def autojit_sample_2(n):\n",
      "    print('arg n: '+ str(numba.typeof(n)))\n",
      "    print('literal 4: ' + str(numba.typeof(4))) \n",
      "    tmp = n + 4;\n",
      "    print('tmp: '+ str(numba.typeof(tmp)))\n",
      "    print('literal 3j:' + str(numba.typeof(3j)))\n",
      "    return tmp + 3j;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(autojit_sample_2(42 + 0j))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: complex128\n",
        "literal 4: int\n",
        "tmp: complex64\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(autojit_sample_2(42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arg n: int\n",
        "literal 4: int\n",
        "tmp: complex64\n",
        "literal 3j:complex128\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Supported types in *numba*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numba supports many different types. Some are *primitive* types in the sense that they map in a natural way to *native* types that can be directly operated by the processor. Others are a bit more complex. Some *types* are not known to *numba*. In that case *numba* uses the type *object* for it. Code generated that involve values of type *object* be way slower, as numba handles these variables as *Python* objects using the Python C API. This section introduces some of the *types* that are supported by *numba*. The *types* pointed out here are just samples, and it is not an exhaustive list of all the types in *numba*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Integral types:\n",
      "\n",
      "<table><tr><th>type</th><th>numba type</th><th>short name</th><th>python equivalent</th></tr>\n",
      "<tr><td>boolean</td><td>numba.bool__</td><td>b1</td><td>bool</td></tr>\n",
      "<tr><td>signed integer</td><td>numba.int__</td><td></td><td>int</td></tr>\n",
      "<tr><td>signed integer (8 bit)</td><td>numba.int8</td><td>i1</td><td></td></tr>\n",
      "<tr><td>signed integer (16 bit)</td><td>numba.int16</td><td>i2</td><td></td></tr>\n",
      "<tr><td>signed integer (32 bit)</td><td>numba.int32</td><td>i4</td><td></td></tr>\n",
      "<tr><td>signed integer (64 bit)</td><td>numba.int64</td><td>i8</td><td></td></tr>\n",
      "<tr><td>unsigned integer</td><td>numba.uint</td><td></td><td></td></tr>\n",
      "<tr><td>unsigned integer (16 bit)</td><td>numba.uint16</td><td>u2</td><td></td></tr>\n",
      "<tr><td>unsigned integer (32 bit)</td><td>numba.uint32</td><td>u4</td><td></td></tr>\n",
      "<tr><td>unsigned integer (64 bit)</td><td>numba.uint64</td><td>u8</td><td></td></tr>\n",
      "</table>\n",
      "\n",
      "floating point types:\n",
      "<table><tr><th>type</th><th>numba type</th><th>short name</th><th>python equivalent</th></tr>\n",
      "<tr><td>single precision floating point (32 bit)</td><td>numba.float32</td><td>f4</td><td></td></tr>\n",
      "<tr><td>double precision floating point (64 bit)</td><td>numba.float64</td><td>f8</td><td>float</td></tr>\n",
      "<tr><td>single precision complex (2 x 32 bit)</td><td>numba.complex64</td><td>c8</td><td></td></tr>\n",
      "<tr><td>double precison complex (2 x 64 bit)</td><td>numba.complex128</td><td>c16</td><td>complex</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some important *Python* types are also supported directly by *numba*, like tuples and lists:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof((32, 16, 15))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "tuple(int, 3)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof([42.0, 37.13, 15.12])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "list(float64, 3)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note how the content of tuples/lists get typed as well. This is done automatically when possible. Due to *Python* dynamic typing it is not always possible to find a common *type* for the contained elements other than *object*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof([42.0, True, \"hello world!\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "list(object, 3)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Types unknown to *numba* will also be treated as *object*. For example, an iterator object is not known as a type for numba:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(xrange(10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "object"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*NumPy arrays* are also understood by *numba*. They are handled efficiently, without relying on the *Python runtime* for indexing/slicing. Note how the short names of types map to NumPy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(np.zeros((10, 10, 10), dtype='c16'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "complex128[:, :, :]"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(np.zeros((1000,), dtype=np.float32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "float32[:]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Numba* also knows about *ctypes* and *cffi*. For example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(ctypes.c_float(42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "float32"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof((ctypes.c_float*4)(32,12,15,11))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "carray(float32, 4)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Specifying types"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In *numba* you may need to *explicitly* specify *types*. There are two main scenarios where a *type* may need to be explicitly specified:\n",
      "\n",
      "* When specifying a *signature* as an argument for the *numba.jit* decorator.\n",
      "* When specifying the *type* of a local variable (in the context of the *locals* keyword.\n",
      "\n",
      "In order to specify the types, you can build the type as an expression in the following way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.long_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "long"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.long_[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "long[:]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.c16"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "complex128"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In that case you are using python to build the objects that represent the type. This means that you have to specify the numba namespace many times, making it hard to read. It is possible to use__ from numba import * __, but that will pollute your namespace quite a lot. You can also just import the types you use.\n",
      "\n",
      "Another option is to put the type specification in a string, in the same way you would write the type if you had made__ from numba import * __. In the places where *numba* expects a *type*, it will accept such a string and build the type from it. So:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit(numba.float32(numba.float32))\n",
      "def add42(x):\n",
      "    return x + 42.0\n",
      "\n",
      "add42.signature"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "float32 (*)(float32)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "is equivalent to:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit('float32(float32)')\n",
      "def add42(x):\n",
      "    return x + 42.0\n",
      "\n",
      "add42.signature"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "float32 (*)(float32)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note also that the short names used in previous samples inside strings are also available from the namespace:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.c8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "complex64"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also note that the signature itself is also a *type*. In fact it is a *function type* that describes the function. So abusing the notation, it is possible to define some weird *types*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.float32(numba.void)(numba.int32(numba.bool_)[:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "float32 (*)(void) (*)(int32 (*)(bool)[:])"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keep in mind that in practice, the *string* notation is equivalent to the one using *objects*. In fact, the former is implemented using the later. So any type that you can specify with one can be specified by the other. I personally find that the conciseness without namespace pollution of the *string* notation is a huge plus."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "An introduction to the *numba* command line tool"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a finishing note, there is a small command line tool, called *numba* that can help understand a bit *type inference* as well as code generation.\n",
      "\n",
      "The *numba* command line tool, which is included with the *numba* package, allows dumping information of code generation of *numba* functions. This can help to better understand what's happening.\n",
      "\n",
      "---\n",
      "    $ numba --help\n",
      "    usage: numba [-h] [--annotate] [--dump-llvm] [--dump-optimized] [--dump-cfg]\n",
      "                 [--dump-ast] [--fancy]\n",
      "                 filename\n",
      "\n",
      "    positional arguments:\n",
      "      filename          Python source filename\n",
      "\n",
      "    optional arguments:\n",
      "      -h, --help        show this help message and exit\n",
      "      --annotate        Annotate source\n",
      "      --dump-llvm       Print generated llvm assembly\n",
      "      --dump-optimized  Dump the optimized llvm assembly\n",
      "      --dump-cfg        Dump the control flow graph\n",
      "      --dump-ast        Dump the AST\n",
      "      --fancy           Try to output fancy files (.dot or .html)\n",
      "---\n",
      "\n",
      "One interesting feature is that of the **--annotate** option, that shows for each line the types for the variables involved, as well as the generated (unoptimized) *llvm* generated code. Don't worry if the generated *llvm* code seems to complex. This is just illustrative and no knowledge of *llvm* is needed in order to use *numba*.\n",
      "\n",
      "Let's take an example:\n",
      "\n",
      "---\n",
      "    @numba.jit('c16(f8)')\n",
      "    def test(x):\n",
      "        tmp = x + 4\n",
      "        return tmp + 5j\n",
      "---\n",
      "\n",
      "Using *numba --annotate* on that code (that resides in *test.py*) results in:\n",
      "\n",
      "---\n",
      "    $ numba --annotate test.py \n",
      "       5    @numba.jit('c16(f8)')\n",
      "       6    def test(x):\n",
      "              -------------------||-------------------\n",
      "              Types: ('x', 'float64')\n",
      "              -------------------||-------------------\n",
      "       7        tmp = x + 4\n",
      "                  -------------------||-------------------\n",
      "                  Types: ('x', 'float64')\n",
      "                  __________________llvm__________________\n",
      "                  entry:\n",
      "                    %1 = fadd double %x, 4.000000e+00\n",
      "                    %4 = extractvalue { double, double } %3, 0\n",
      "                    %5 = extractvalue { double, double } %3, 1\n",
      "                    %6 = fadd double %4, 0.000000e+00\n",
      "                    %7 = fadd double %5, 5.000000e+00\n",
      "                    %8 = insertvalue { double, double } undef, double %6, 0\n",
      "                    %9 = insertvalue { double, double } %8, double %7, 1\n",
      "                  -------------------||-------------------\n",
      "       8        return tmp + 5j\n",
      "                  -------------------||-------------------\n",
      "                  Types: ('tmp', 'float64') ('return', 'complex128')\n",
      "                  __________________llvm__________________\n",
      "                  entry:\n",
      "                    %2 = insertvalue { double, double } undef, double %1, 0\n",
      "                    %3 = insertvalue { double, double } %2, double 0.000000e+00, 1\n",
      "                    store { double, double } %9, { double, double }* %0\n",
      "                    br label %cleanup_label\n",
      "                  cleanup_label:\n",
      "                    ret void\n",
      "                  -------------------||-------------------\n",
      "---\n",
      "\n",
      "You can see how, following each line of code and before the equivalent llvm code for it, there is a *Types* line that enumerates the variables involved in that line as well as the inferred type.\n",
      "\n",
      "Remember that the *llvm code* in **--annotate** is unoptimize. Using **--dump-optimized** it is possible to see the actual code generated after optimization:\n",
      "\n",
      "---\n",
      "    $ numba --dump-optimized test.py \n",
      "\n",
      "    ; Function Attrs: nounwind\n",
      "    define void @__numba_specialized_0_test(double %x, { double, double }* nocapture) #0 {\n",
      "    entry:\n",
      "      %1 = fadd double %x, 4.000000e+00\n",
      "      %2 = fadd double %1, 0.000000e+00\n",
      "      %3 = insertvalue { double, double } undef, double %2, 0\n",
      "      %4 = insertvalue { double, double } %3, double 5.000000e+00, 1\n",
      "      store { double, double } %4, { double, double }* %0, align 8\n",
      "      ret void\n",
      "    }\n",
      "---\n",
      "\n",
      "Pretty simple code, as has to be expected for such a simple function.\n",
      "\n",
      "As has been mentioned, code involving *object* types generate code that is worse, because it has to rely on the *Python runtime*, making the resulting function *larger* and *slower*. With the *numba* command line tool we can get a glimpse of this. Let's try compiling the same function, but forcing *tmp* to be of type *object*:\n",
      "\n",
      "---\n",
      "    @numba.jit('c16(f8)', locals={'tmp': 'O')\n",
      "    def test(x):\n",
      "        tmp = x + 4\n",
      "        return tmp + 5j\n",
      "---\n",
      "\n",
      "This results in:\n",
      "\n",
      "---\n",
      "    $ numba --annotate test.py \n",
      "       5    @numba.jit('c16(f8)', locals={'tmp': numba.object_})\n",
      "       6    def test(x):\n",
      "              -------------------||-------------------\n",
      "              Types: ('x', 'float64')\n",
      "              -------------------||-------------------\n",
      "       7        tmp = x + 4\n",
      "                  -------------------||-------------------\n",
      "                  Python C API: 2\n",
      "                  Types: ('x', 'float64') ('tmp', 'object')\n",
      "                  __________________llvm__________________\n",
      "                  entry:\n",
      "                    %objtemp = alloca { i64, i8* }*\n",
      "                    %1 = fadd double %x, 4.000000e+00\n",
      "                    %2 = call { i64, i8* }* @PyFloat_FromDouble(double %1)\n",
      "                    store { i64, i8* }* %2, { i64, i8* }** %objtemp, !tbaa !2\n",
      "                    %3 = ptrtoint { i64, i8* }* %2 to i64\n",
      "                    %4 = icmp eq i64 %3, 0\n",
      "                    br i1 %4, label %error_label, label %\"no_error_7:10\"\n",
      "                  cleanup_label:\n",
      "                    %5 = load { i64, i8* }** %objtemp, !tbaa !2\n",
      "                    call void @Py_XDECREF({ i64, i8* }* %5)\n",
      "                  no_error_7:10:\n",
      "                    %8 = load { i64, i8* }** %objtemp, !tbaa !2\n",
      "                    call void @Py_INCREF({ i64, i8* }* %8)\n",
      "                    %9 = load { i64, i8* }** %var_tmp, !tbaa !2\n",
      "                    call void @Py_XDECREF({ i64, i8* }* %9)\n",
      "                    store { i64, i8* }* %8, { i64, i8* }** %var_tmp, !tbaa !3\n",
      "                    br label %empty\n",
      "                  empty:\n",
      "                    %11 = icmp eq i64 %10, 0\n",
      "                    br i1 %11, label %empty3, label %empty2\n",
      "                  empty2:\n",
      "                    %12 = load { i64, i8* }** %var_tmp, !tbaa !2\n",
      "                  empty3:\n",
      "                    call void @PyErr_SetString({ i64, i8* }* inttoptr (i64 4296486848 to { i64, i8* }*), i8* getelementptr inbounds ([10 x i8]* @__STR_0, i32 0, i32 0))\n",
      "                    br label %error_label\n",
      "                  -------------------||-------------------\n",
      "       8        return tmp + 5j\n",
      "                  -------------------||-------------------\n",
      "                  Python C API: 4\n",
      "                  Types: ('return', 'complex128')\n",
      "                  __________________llvm__________________\n",
      "                  entry:\n",
      "                    %objtemp4 = alloca { i64, i8* }*\n",
      "                    %objtemp1 = alloca { i64, i8* }*\n",
      "                  cleanup_label:\n",
      "                    %6 = load { i64, i8* }** %objtemp4, !tbaa !2\n",
      "                    call void @Py_XDECREF({ i64, i8* }* %6)\n",
      "                    %7 = load { i64, i8* }** %objtemp1, !tbaa !2\n",
      "                    call void @Py_XDECREF({ i64, i8* }* %7)\n",
      "                    ret void\n",
      "                  no_error_7:10:\n",
      "                    %10 = ptrtoint { i64, i8* }** %var_tmp to i64\n",
      "                  empty2:\n",
      "                    %13 = call { i64, i8* }* @PyComplex_FromDoubles(double 0.000000e+00, double 5.000000e+00)\n",
      "                    store { i64, i8* }* %13, { i64, i8* }** %objtemp4, !tbaa !2\n",
      "                    %14 = ptrtoint { i64, i8* }* %13 to i64\n",
      "                    %15 = icmp eq i64 %14, 0\n",
      "                    br i1 %15, label %error_label, label %\"no_error_8:11\"\n",
      "                  no_error_8:11:\n",
      "                    %16 = load { i64, i8* }** %objtemp4, !tbaa !2\n",
      "                    %17 = call { i64, i8* }* @PyNumber_Add({ i64, i8* }* %12, { i64, i8* }* %16)\n",
      "                    store { i64, i8* }* %17, { i64, i8* }** %objtemp1, !tbaa !2\n",
      "                    %18 = ptrtoint { i64, i8* }* %17 to i64\n",
      "                    %19 = icmp eq i64 %18, 0\n",
      "                    br i1 %19, label %error_label, label %\"no_error_8:115\"\n",
      "                  no_error_8:115:\n",
      "                    %20 = load { i64, i8* }** %objtemp1, !tbaa !2\n",
      "                    %21 = call double @PyComplex_RealAsDouble({ i64, i8* }* %20)\n",
      "                    %22 = call double @PyComplex_ImagAsDouble({ i64, i8* }* %20)\n",
      "                    %23 = insertvalue { double, double } undef, double %21, 0\n",
      "                    %24 = insertvalue { double, double } %23, double %22, 1\n",
      "                    store { double, double } %24, { double, double }* %0\n",
      "                    br label %cleanup_label\n",
      "                  -------------------||-------------------\n",
      "---\n",
      "\n",
      "It is possible to see in the *Types* how *tmp* was forced into an *object*. It is also apparent how much complex the function results. There are a number of calls to the *Python* runtime (*call* function to CPython's C API functions). Even with optimizations the result is way more complex:\n",
      "\n",
      "---\n",
      "    $ numba --dump-optimized test.py \n",
      "\n",
      "    define void @__numba_specialized_0_test(double %x, { double, double }* nocapture) {\n",
      "    entry:\n",
      "      %1 = fadd double %x, 4.000000e+00\n",
      "      %2 = tail call { i64, i8* }* @PyFloat_FromDouble(double %1)\n",
      "      %3 = icmp eq { i64, i8* }* %2, null\n",
      "      br i1 %3, label %cleanup_label, label %\"no_error_7:10\"\n",
      "\n",
      "    cleanup_label:                                    ; preds = %entry, %\"no_error_7:10\", %\"no_error_8:11\", %\"no_error_8:115\"\n",
      "      %objtemp4.0.load911 = phi { i64, i8* }* [ %4, %\"no_error_8:115\" ], [ %4, %\"no_error_8:11\" ], [ null, %\"no_error_7:10\" ], [ null, %entry ]\n",
      "      %objtemp1.0.load810 = phi { i64, i8* }* [ %6, %\"no_error_8:115\" ], [ null, %\"no_error_8:11\" ], [ null, %\"no_error_7:10\" ], [ null, %entry ]\n",
      "      %storemerge = phi { double, double } [ %11, %\"no_error_8:115\" ], [ { double 0x419D6F3454000000, double 0.000000e+00 }, %\"no_error_8:11\" ], [ { double 0x419D6F3454000000, double 0.000000e+00 }, %\"no_error_7:10\" ], [ { double 0x419D6F3454000000, double 0.000000e+00 }, %entry ]\n",
      "      store { double, double } %storemerge, { double, double }* %0, align 8\n",
      "      tail call void @Py_XDECREF({ i64, i8* }* %2)\n",
      "      tail call void @Py_XDECREF({ i64, i8* }* %objtemp4.0.load911)\n",
      "      tail call void @Py_XDECREF({ i64, i8* }* %objtemp1.0.load810)\n",
      "      ret void\n",
      "\n",
      "    \"no_error_7:10\":                                  ; preds = %entry\n",
      "      tail call void @Py_INCREF({ i64, i8* }* %2)\n",
      "      tail call void @Py_XDECREF({ i64, i8* }* null)\n",
      "      %4 = tail call { i64, i8* }* @PyComplex_FromDoubles(double 0.000000e+00, double 5.000000e+00)\n",
      "      %5 = icmp eq { i64, i8* }* %4, null\n",
      "      br i1 %5, label %cleanup_label, label %\"no_error_8:11\"\n",
      "\n",
      "    \"no_error_8:11\":                                  ; preds = %\"no_error_7:10\"\n",
      "      %6 = tail call { i64, i8* }* @PyNumber_Add({ i64, i8* }* %2, { i64, i8* }* %4)\n",
      "      %7 = icmp eq { i64, i8* }* %6, null\n",
      "      br i1 %7, label %cleanup_label, label %\"no_error_8:115\"\n",
      "\n",
      "    \"no_error_8:115\":                                 ; preds = %\"no_error_8:11\"\n",
      "      %8 = tail call double @PyComplex_RealAsDouble({ i64, i8* }* %6)\n",
      "      %9 = tail call double @PyComplex_ImagAsDouble({ i64, i8* }* %6)\n",
      "      %10 = insertvalue { double, double } undef, double %8, 0\n",
      "      %11 = insertvalue { double, double } %10, double %9, 1\n",
      "      br label %cleanup_label\n",
      "    }\n",
      "---\n",
      "\n",
      "Bear in mind that it is not only the generated code, but calls into the *Python runtime* that will add to the execution time of the function.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}