{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "NumPy and numba"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import numba\n",
      "import numpy as np\n",
      "import math\n",
      "import llvm\n",
      "import ctypes\n",
      "print(\"numba version: %s \\nNumPy version: %s\\nllvm version: %s\" % (numba.__version__,np.__version__, llvm.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "numba version: 0.11.1-19-g77827c7 \n",
        "NumPy version: 1.7.1\n",
        "llvm version: 0.12.0\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_NumPy_ provides a compact, typed container for homogenous arrays of data. This is ideal to store data homogeneous data in *Python* with little overhead. _NumPy_ also provides a set of functions that allows manipulation of that data, as well as operating over it. There is a rich ecosystem around _Numpy_ that results in fast manipulation of _Numpy arrays_, as long as this manipulation is done using pre-baked operations (that are typically vectorized). This operations are usually provided by extension modules and written in C, using the _Numpy C API_.\n",
      "\n",
      "_numba_ allows generating native code from Python functions just by adding decorators. This code is wrapped and directly callable from within Python.\n",
      "\n",
      "There are many cases where you want to apply code to your _NumPy_ data, and need that code to execute fast. You may get lucky and have the functions you want already written in the extensive _NumPy_ ecosystem. Otherwise you will end with some code that is not that fast, but that you can improve execution time by writing code the \"NumPy way\". If it is not fast enough, you can write an extension module using the _Numpy C API_. Writing an extension module will take quite a bit of time, and forces you to a slow compile-install-test cycle.\n",
      "\n",
      "Wouldn't it be great if you could just write code in *Python* that describes your function and execute it at speed similar to that of what you could achieve with the extension module, all without leaving the *Python interpreter*? _numba_ allows that.\n",
      "\n",
      "_Numba_ is _NumPy_ aware. This means:\n",
      "\n",
      "- It natively understands _NumPy_ arrays, shapes and dtypes. *NumPy* arrays are supported as native types.\n",
      "- It knows how to index/slice a _NumPy_ array without relying on *Python*.\n",
      "- It provides supports for generating _ufuncs_ and _gufuncs_ from inside the *Python* interpreter."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "_Numba_ understands _NumPy_ arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NumPy arrays are understood by numba. By using the *numba.typeof* we can see that numba not only knows about the arrays themshelves, but also about its shape and underlying dtypes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array = np.arange(2000, dtype=np.float_)\n",
      "numba.typeof(array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "float64[:]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(array.reshape((2,10,100)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "float64[:, :, :]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that for *numba* the underlying dtype is the base type of the array. The number of dimensions is also part of the type, but the *arity* of each dimension is not. That is, the lenght of the tuple defining the shape is part of the the type, but not the elements of that tuple. So:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(array.reshape((2,10,100))) == numba.typeof(array.reshape((4,10,50)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba.typeof(array.reshape((2,10,100))) == numba.typeof(array.reshape((40,50)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "_Numba_ knows how to index and slice a _Numpy_ array natively"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indexing and slicing of _NumPy arrays_ are handled natively by _numba_. This means that it is possible to _index_ and _slice_ a _Numpy array_ in _numba_ compiled code without relying on the _Python runtime_. In practice this means that _numba_ code running on _NumPy arrays_ will execute with a level of efficiency close to that of C.\n",
      "\n",
      "Let's make a simple function that uses indexing. For example a really naive implementation of a sum:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sum_all(A):\n",
      "    \"\"\"Naive sum of elements of an array... assumes one dimensional array of floats\"\"\"\n",
      "    acc = 0.0\n",
      "    for i in xrange(A.shape[0]):\n",
      "        acc += A[i]\n",
      "    return acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_array = np.arange(10000.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _pure Python_ approach of this naive function is quite underwhelming speed-wise:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sum_all(sample_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 5.53 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we relied on _NumPy_ it would be much faster:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit np.sum(sample_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 20.2 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But with _numba_ the speed of that _naive_ code is quite good:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_all_jit = numba.jit('float64(float64[:])')(sum_all)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sum_all_jit(sample_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 loops, best of 3: 11.8 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is in part possible because of the native support for indexing in _numba_. The function can be compiled in a nopython context, that makes it quite fast:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_all_jit = numba.jit('float64(float64[:])', nopython=True)(sum_all)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "_Numba_ supports generating _NumPy_ _ufuncs_ and _gufuncs_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In _NumPy_ there are universal functions([_ufuncs_](http://docs.scipy.org/doc/numpy/reference/ufuncs.html)) and generalized universal functions ([_gufuncs_](http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html)). \n",
      "\n",
      "- _ufuncs_ are quite established and allows mapping of scalar operations over _NumPy_ arrays. The resulting vectorized operation follow _Numpy_'s broadcasting rules.\n",
      "\n",
      "- _gufuncs_ are a generalization of _ufuncs_ that allow vectorization of _kernels_ that work over the inner dimensions of the arrays. In this context a _ufunc_ would just be a _gufunc_ where all the operands of its kernels have 0 dimensions (i.e. are scalars).\n",
      "\n",
      "_ufuncs_ and _gufuncs_ are typically built using _Numpy's C API_. _Numba_ offers the possibility to create _ufuncs_ and _gufuncs_ within the Python interpreter, using Python functions to describe the _kernels_. To access this functionality _numba_ provides the *vectorize* decorator and the *GUVectorize* class."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The *vectorize* decorator"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*vectorize* is the decorator to be used to build *ufuncs*. Note that as of this writing, it is not in the numba namespace, but in *numba.vectorize*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numba.vectorize import vectorize\n",
      "\n",
      "print(vectorize.__doc__)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "vectorize(type_signatures[, target='cpu'])\n",
        "\n",
        "    A decorator to create numpy ufunc object from Numba compiled code.\n",
        "    \n",
        "    :param type_signatures: an iterable of type signatures, which are either \n",
        "                            function type object or a string describing the \n",
        "                            function type.\n",
        "    \n",
        "    :param target: a string for hardware target; e.g. \"cpu\", \"parallel\", \"gpu\".\n",
        "                   For support for \"parallel\" and \"gpu\", use NumbaPro.\n",
        "\n",
        "    :returns: a vectorizers object.\n",
        "    \n",
        "    Example::\n",
        "\n",
        "        @vectorize(['float32(float32, float32)',\n",
        "                    'float64(float64, float64)'])\n",
        "        def sum(a, b):\n",
        "            return a + b\n",
        "    \n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Its usage is pretty simple, just write the scalar function you want for your _ufunc_. Then just decorate it with _vectorize_, passing as a parameter the signatures you want your code to be generated. The generated _ufunc_ will be handled as any other _NumPy_ _ufunc_. That means that type promotions and broadcasting rules follow those of _NumPy_."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For example, let's write a sample ufunc that performs a lineal interpolation between A and B. The 'kernel' will look like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lerp(A,B,factor):\n",
      "    \"\"\"interpolates A and B by factor\"\"\"\n",
      "    return (1-factor)*A + factor*B"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lerp(0.0, 10.0, 0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "3.0"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's do a _ufunc_ for the floating point types. I will be using vectorize as a function, but remember that you could just add the decorator in the definition of the kernel itself."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lerp_ufunc = vectorize(['float32(float32, float32, float32)', 'float64(float64, float64, float64)'])(lerp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can run our lerp with all of _NumPy_'s niceties, like broadcasting of one operand (in this case the factor)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.arange(0.0, 100000.0, 2.0)\n",
      "B = np.arange(100000.0, 0.0, -2.0)\n",
      "F = np.array([0.5] * 50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lerp_ufunc(A,B,0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([ 50000.,  50000.,  50000., ...,  50000.,  50000.,  50000.])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also quite fast:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit lerp_ufunc(A, B, 0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 210 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit lerp(A, B, 0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 241 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that in this case the same original function can be used to generate the _ufunc_ and to execute the equivalent _NumPy_ vectorized version.  When executing there will be differences in how the expression is evaluated.\n",
      "\n",
      "When using _NumPy_ the expression is evaluated one operation at a time, over the entire vector. _Numba_ generated code will evaluate the full expression in one go, for each element. The _numba_ approach approach avoids having temporal intermmediate arrays built, as well as avoiding revisiting operands that are being used more than once in a expression. This is useful with big arrays of data where there will be savings in process memory usage as well as better cache usage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sample_poly(x):\n",
      "    return x - x*x*x/6.0 + x*x*x*x*x/120.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S = np.arange(0, np.pi, np.pi/36000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_poly_ufunc = vectorize(['float32(float32)', 'float64(float64)'])(sample_poly)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sample_poly(S)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 2.33 s per loop\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sample_poly_ufunc(S)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 520 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also worth noting that numba's _vectorize_ provides similar convenience to that of NumPy's _vectorize_, but with performance similar to an _ufunc_.\n",
      "\n",
      "For example, let's take the example in [NumPy's vectorize documentation](http://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def myfunc(a, b):\n",
      "    \"Return a-b if a>b, otherwise return a+b\"\n",
      "    if a > b:\n",
      "        return a - b\n",
      "    else:\n",
      "        return a + b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myfunc_input = np.arange(100000.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy_vec_myfunc = np.vectorize(myfunc) \n",
      "%timeit numpy_vec_myfunc(myfunc_input, 50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 30.2 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba_vec_myfunc = vectorize(['float64(float64, float64)'])(myfunc)\n",
      "%timeit numba_vec_myfunc(myfunc_input, 50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 348 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The GUVectorize class"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the same way the _vectorize_ allows building _NumPy_'s _ufuncs_ from inside the Python interpreter just by writing the expression that forms the kernel; _GUVectorize_ allows building _Numpy_'s _gufuncs_ without the need of writing a C extension module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numba.vectorize import GUVectorize\n",
      "print(GUVectorize.__doc__)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    Vectorizer for generalized ufuncs.\n",
        "    \n"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[_Generalized universal functions_](http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html) require a _dimension signature_ for the _kernel_ they implement. Do not confuse this _dimension signature_ with the _type signature_ that _numba_ requires.\n",
      "\n",
      "When building a _gufunc_ you start by writing the kernel function. Then instantiate _GUVectorize_ with the _kernel_ and the _dimension signature_ of that _kernel_. Then use the method _add_ to add _type signatures_ that you want the _gufunc_ to support.\n",
      "\n",
      "For example, let's make a matrix multiplication kernel, notice that the last argument is the array where to place the result"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def matmulcore(A, B, C):\n",
      "    m, n = A.shape\n",
      "    n, p = B.shape\n",
      "    for i in range(m):\n",
      "        for j in range(p):\n",
      "            C[i, j] = 0\n",
      "            for k in range(n):\n",
      "                C[i, j] += A[i, k] * B[k, j]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, instantiate _GUVectorize_. Pass the function to act as _kernel_, as well as the _dimension signature_ for the _kernel_. You can check the signature format in [NumPy's documentation](http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gu_builder = GUVectorize(matmulcore, '(m,n),(n,p)->(n,p)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the _add_ method in the builder to add _type signatures_ to the generated _gufuncs_. The types, unlike in other parts of _numba_, must be specified as a list with the types for each of the arguments as seen in the _kernel_ function. Remember, return values are last. This sample will compile the kernel for float64 (double precision) and for float32 (single precision):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gu_builder.add(argtypes=[numba.float64[:,:], numba.float64[:,:], numba.float64[:,:]])\n",
      "gu_builder.add(argtypes=[numba.float32[:,:], numba.float32[:,:], numba.float32[:,:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After all the desired _type signatures_ are added, we can build the gufunc by calling the method _build_ufunc_:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gu_matmul = gu_builder.build_ufunc()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result is a _gufunc_, that can be used as any othe _gufunc_ in _NumPy_. Broadcasting and type promotion rules are those on _NumPy_."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matrix_ct = 10000\n",
      "gu_test_A = np.arange(matrix_ct * 2 * 4, dtype=np.float32).reshape(matrix_ct, 2, 4)\n",
      "gu_test_B = np.arange(matrix_ct * 4 * 5, dtype=np.float32).reshape(matrix_ct, 4, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit gu_matmul(gu_test_A, gu_test_B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 2.27 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Caveats"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are some points to take into account when dealing with _NumPy_ arrays inside _numba_ compiled functions:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "No range checks when indexing in _numba_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In _numba_ generated code **no range checking is performed when indexing**. No range checking is performed as to allow generating code that performs better. So you need to be careful about the code as any indexing that goes out of range can cause a bad-access or a memory overwrite, potentially *crashing* the interpreter process."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = np.arange(16.0).reshape((2,8))\n",
      "print(arr)\n",
      "print(arr.strides)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.   1.   2.   3.   4.   5.   6.   7.]\n",
        " [  8.   9.  10.  11.  12.  13.  14.  15.]]\n",
        "(64, 8)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As indexing in Python is 0-based, the following line will cause an exception error, as arr.shape[1] is 8, and the range for the column number is (0..7):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr[0, arr.shape[1]] = 42.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 8 is out of bounds for axis 1 with size 8",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-06c1e5ef06d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, as _numba_ doesn't have range checks, it will index anyways. As the index is out of bounds, and the array is in C order, the value will overflow into the next row. In this case, in the place reserved for element (1, 0)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@numba.jit(\"void(f8[:,:])\")\n",
      "def bad_access(array):\n",
      "    array[0, array.shape[1]] = 42.0\n",
      "bad_access(arr)\n",
      "print(arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.   1.   2.   3.   4.   5.   6.   7.]\n",
        " [ 42.   9.  10.  11.  12.  13.  14.  15.]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this sample case we where lucky, as the _out-of-bounds_ access fell into the allocated range. Unchecked indexing can potentially cause illegal accesses and crash the process running the *Python interpreter*. However, it allows for code generation that produces faster code."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
